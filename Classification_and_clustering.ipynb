{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUUfncnGdbU4"
   },
   "source": [
    "# Clustering and classification in Python üêç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFWdWETBdhaH"
   },
   "source": [
    "This notebook introduces basic clustering algorithm in Python using Scikit-learn module. At first, we have to import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYM_XoMpdXIh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxyPOIAQocZ9"
   },
   "source": [
    "The first step is to generate data needed for the presentation. Specify number of clusters to be generated by specifying `no_clusters` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZBTdWbhooVc"
   },
   "outputs": [],
   "source": [
    "no_clusters = 5\n",
    "X, Y = make_blobs(n_samples=200, centers=no_clusters,\n",
    "                  n_features=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "MmkJZNSfdY5g",
    "outputId": "eb552b4f-313c-4a05-cb5a-a4942014f7d4"
   },
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X[:,0], y=X[:,1], hue=Y, palette='bright')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGwQExWVosII"
   },
   "source": [
    "## K-means clustering training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bY9ufCN1owPk"
   },
   "source": [
    "In the code below, we train k-means clustering model using scikit-learn library. We do it for several different numbers of clusters, to find optimum numbers of center points that minimize the inertia of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "E9Nau2BueTaV",
    "outputId": "b3e7d57a-83aa-4294-959e-3fe8ecb22a85"
   },
   "outputs": [],
   "source": [
    "cluster_range = range(1, no_clusters * 2)\n",
    "distortions = []\n",
    "for n_clusters in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=10)\n",
    "    kmeans.fit(X)\n",
    "    distortions.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=cluster_range, y=distortions, marker='o')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Distortion (Inertia)')\n",
    "plt.ylim(0, max(distortions))\n",
    "plt.xticks(range(1, max(cluster_range) + 1))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grNZEyMZpBjN"
   },
   "source": [
    "## Cluster visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoXgHp0mhysn"
   },
   "source": [
    "You can select the value of `optimal_k` to see the clustering graph. You can select any integer value here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xGCDxgfpNlF"
   },
   "source": [
    "### Plotting blobs for different numbers of centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 999
    },
    "id": "7H4jExblhKPn",
    "outputId": "a58d0683-5277-438a-c2c8-b488c0049ebe"
   },
   "outputs": [],
   "source": [
    "k_values = [i for i in range(1,no_clusters + 2)]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Clustering for Different Optimal K', fontsize=16)\n",
    "\n",
    "for i, k in enumerate(k_values):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0, n_init=10)\n",
    "    kmeans.fit(X)\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    sns.set(style='whitegrid')\n",
    "    scatterplot = sns.scatterplot(x=X[:,0], y=X[:,1],\n",
    "                                  hue=kmeans.labels_, palette='bright',\n",
    "                                  legend='full', ax=ax)\n",
    "    ax.set_title(f'Optimal K = {k}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    ax.scatter(cluster_centers[:, 0], cluster_centers[:, 1],\n",
    "               s=200, c='black', marker='x', label='Cluster Centers')\n",
    "    ax.legend()\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4AGGhs0hxA1"
   },
   "outputs": [],
   "source": [
    "optimal_k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "dHsupoorebg-",
    "outputId": "8a27774b-3fd3-47f5-f780-60d5e08d9155"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=optimal_k, random_state=0, n_init=10)\n",
    "kmeans.fit(X)\n",
    "sns.set(style='whitegrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatterplot = sns.scatterplot(x=X[:,0], y=X[:,1],\n",
    "                              hue=kmeans.labels_, palette='bright',\n",
    "                              legend='full')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1],\n",
    "            s=200, c='black', marker='x', label='Cluster Centers')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gORbfx8RhhFB"
   },
   "source": [
    "## Classification of blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X_train[:, 0], y=X_train[:, 1], hue=Y_train, palette='bright')\n",
    "sns.scatterplot(x=X_test[:, 0], y=X_test[:, 1], color='black', marker='x')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "Yhat = logreg.predict(X_test)\n",
    "print(f\"Accuracy for the train set: {logreg.score(X_train, Y_train)}\")\n",
    "print(f\"Accuracy for the test set: {logreg.score(X_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'X1': X_test[:,0], 'X2': X_test[:,1], 'Y' : Y_test, 'Yhat' : Yhat}\n",
    "predictions = pd.DataFrame(data)\n",
    "misclassified = predictions[Yhat != Y_test]\n",
    "correct = predictions[Yhat == Y_test]\n",
    "print(misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=correct['X1'], \n",
    "                y=correct['X2'], \n",
    "                hue=correct['Y'], \n",
    "                palette='bright',\n",
    "                label='Classified correctly')\n",
    "sns.scatterplot(x=misclassified['X1'], \n",
    "                y=misclassified['X2'], \n",
    "                hue=misclassified['Y'], \n",
    "                palette='bright', \n",
    "                marker='x',\n",
    "               label='Misclassified')\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNC9ZNAkvKL+p2ePKA4/KkW",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
